# SynaLinks
## Pioneering Safe Neuro-Symbolic Artificial General Intelligence
[![Discord](https://dcbadge.vercel.app/api/server/zM2rEfsqxj)](https://discord.gg/zM2rEfsqxj)

*SynaLinks* is a French startup from Toulouse founded in 2023, capitalizing on recent scientific advancements in natural language processing. Hailing from the technological hub in France, our core mission is to promote a thoughtful and responsible approach to Artificial General Intelligence (AGI). By integrating language models with the established field of symbolic AI, we strive to represent and explain complex problems in a human-comprehensible form.

At *SynaLinks*, we are committed to shaping an ethical and secure future for hybrid AGI. Our expertise in robotics and human-robot interaction allows us to create AGIs that interact harmoniously with humans while leveraging the advanced functionalities of deep learning and symbolic AI. We aim to develop AI solutions that are not only capable but also transparent and aligned with human values, addressing the most complex challenges of our society responsibly.

As we venture into the realm of AGI, we recognize the importance of staying abreast of the latest research and collaborating with industry experts. We are dedicated to continuously assessing and mitigating potential risks associated with AGI, ensuring the safety and beneficial impact of this transformative technology.

*SynaLinks* is at the forefront of the AGI movement, pioneering a path towards safe and responsible AGI development. Through our innovative approach and unwavering commitment to ethical principles, we aim to create a positive and enduring impact on society.

As part of this mission, we are currently developing several free and open-source products:

- **[HybridAGI-knowledge](https://github.com/SynaLinks/HybridAGI-knowledge)**: A hybrid vector and graph database for AGI systems powered by Redis, allowing Agents to navigate and work within their memory in a unix-like fashion.

- **[HybridAGI](https://github.com/SynaLinks/HybridAGI)**: A programmable neuro-symbolic AGI system, that can operate safely, available under a free and open-source license.

- **[HybridAGI-app](https://github.com/SynaLinks/HybridAGI-app)**: A Streamlit App to interact with HybridAGI.

*Obviously, more projects focused on these aspects will emerge... stay tuned!*

## Roadmap

### Phase 1: Strengthening Core Functionality

In this phase, our primary focus will be on improving the core capabilities of the system to ensure a robust foundation for future developments.

- **Enhancing Self-Programming Capabilities**:
We are committed to pushing the boundaries of our system's self-programming capabilities. By leveraging HybridAGI graph programs, we aim to enable our system to imagine, develop and test its own graph programs. This means the system will become more efficient, adaptive, and capable of handling a broader range of tasks.

- **Developing a Fast Text-Only Language Model (LLM) with Large Context Size**:
In the context of HybridAGI, we recognize the significance of a dedicated language model tailored to text-based tasks. We will focus on creating an ultra-fast LLMs capable of processing vast amounts of text data efficiently. This LLM will be designed with extra-large context size, enabling HybridAGI to reason on longer programs and provide more accurate responses. We plan to train two different LLM, one for decision making and the other for acting allowing us to optimize speed and efficiency.

### Phase 2: Multimodal Support & Robotics Applications

Building on the strengthened core, we will focus on introducing multimodal support to the system, opening up exciting possibilities for diverse data types.

- **Adding Multimodal Support**:
We'll integrate support for various data modalities, including images, audio, and more. This enhancement will enable users to work with a rich array of data, enhancing the versatility and utility of the system.

- **Integrating External Tools for Multimodal Support**:
To ensure seamless handling and processing of different data modalities, we will collaborate with external tools and libraries specialized in multimodal data. This integration will allow users to leverage cutting-edge technologies within our system.

## Contact Us

We're constantly striving to improve and expand our project, and these roadmap milestones are just a glimpse of what's in store for the future. We highly value feedback and suggestions from our community, so if you have any ideas or feature requests, please feel free to open an issue or reach out to our team. Together, we'll create a powerful and versatile platform that meets the needs of various users and use cases. Stay tuned for more updates as we make progress on this exciting journey!
